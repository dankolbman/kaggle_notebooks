{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, manifold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(8888)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load different feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dat = pd.read_csv('features/basic_train.csv')\n",
    "test_dat = pd.read_csv('features/basic_test.csv')\n",
    "\n",
    "train_labels = np.load('train_labels_parsed.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dat = pd.read_csv('features/zeros_ones_train.csv')\n",
    "test_dat = pd.read_csv('features/zeros_ones_test.csv')\n",
    "\n",
    "train_labels = np.load('features/train_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dat = pd.read_csv('features/cat_sums_train.csv')\n",
    "test_dat = pd.read_csv('features/cat_sums_test.csv')\n",
    "\n",
    "train_labels = np.load('features/train_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_dat = pd.read_csv('features/trimmed_train.csv')\n",
    "test_dat = pd.read_csv('features/trimmed_test.csv')\n",
    "\n",
    "#train_labels = np.load('features/train_labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold out data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samp = int(len(train_dat)*1.0)\n",
    "print(len(train_dat),'total samples')\n",
    "print(samp,'used for training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xg_train = xgb.DMatrix( train_dat.iloc[:samp].as_matrix(), label=train_labels[:samp])\n",
    "xg_test = xgb.DMatrix( train_dat.iloc[samp:].as_matrix(), label=train_labels[samp:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param = {   'objective': 'binary:logistic',\n",
    "            'eval_metric': 'auc',\n",
    "            'booster': 'gbtree',\n",
    "            'nthread':4,\n",
    "            'max_depth':8,\n",
    "            'colsample_bytree':0.77,\n",
    "            'subsample':0.83,\n",
    "            'eta':0.023,\n",
    "            'gamma': 0.0001\n",
    "        }\n",
    "watchlist = [ (xg_train, 'train') ]#, (xg_test, 'test') ]\n",
    "num_round = 1800\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist, early_stopping_rounds=1000)\n",
    "bst.save_model('{}rounds.model'.format(num_round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xg_pred = xgb.DMatrix( test_dat.as_matrix())\n",
    "print(len(test_dat))\n",
    "\n",
    "pred = bst.predict(xg_pred)\n",
    "sample = pd.read_csv('sample_submission.csv')\n",
    "print(len(sample))\n",
    "sample.QuoteConversion_Flag = pred\n",
    "sample.to_csv('xgb_gamma.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on 95% data\n",
    "- Ones and zeros sums - 1800 rounds 0.969 cv (0.96778 LB)\n",
    "- Category sums - 1800 rounds 0.969296 cv (0.96770 LB)\n",
    "- Trimmed - 1800 rounds 0.969328 cv (0.956 LB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bst = xgb.Booster()\n",
    "bst.load_model('pure_06.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(bst)\n",
    "plt.gcf().set_size_inches((10,50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim unimportant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = sorted(bst.get_fscore().items(), key=lambda x: x[1],reverse=True)\n",
    "print(cols)\n",
    "# Trim off unimportant features\n",
    "cols = cols[:230]\n",
    "# Transforms feature names (f0, f1, ..., f276) to column names (SalesField8, ...)\n",
    "cols = [ train_dat.columns[int(i.replace('f',''))] for i,j in cols ]\n",
    "xg_train = xgb.DMatrix( train_dat[cols][:samp].as_matrix(), label=train_labels[:samp])\n",
    "xg_test = xgb.DMatrix( train_dat[cols][samp:].as_matrix(), label=train_labels[samp:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('important_cols.npy', cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = list(np.load('important_cols.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param = {   'objective': 'binary:logistic',\n",
    "            'eval_metric': 'auc',\n",
    "            'nthread':4,\n",
    "            'max_depth':6,\n",
    "            'colsample_bytree':0.75,\n",
    "            'subsample':0.83,\n",
    "            'min_child_weight':4,\n",
    "            'eta':0.01,\n",
    "        }\n",
    "watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "num_round = 6000\n",
    "model = xgb.train(param, xg_train, num_round, watchlist, early_stopping_rounds=150)\n",
    "model.save_model('trimmed_{}rounds.model'.format(num_round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xg_pred = xgb.DMatrix( test_dat.as_matrix())\n",
    "\n",
    "pred = model.predict(xg_pred)\n",
    "sample = pd.read_csv('sample_submission.csv')\n",
    "sample.QuoteConversion_Flag = pred\n",
    "sample.to_csv('xgb_trimmed_06.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.966560 after 953 rounds using params for pure_03 (`trimmed_03.model`, `trimmed_03.csv`)\n",
    "\n",
    "- 0.9593 after 10 rounds and removing   20 least important features\n",
    "- 0.9594 after 10 rounds and removing   30 least important features\n",
    "- 0.959489 after 10 rounds and removing 40 least important features\n",
    "- 0.959701 after 10 rounds and removing 50 least important features\n",
    "- 0.963020 after 100 rounds and removing 50 least important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(model)\n",
    "plt.gcf().set_size_inches((10,50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Try grouping similiar fields (PersonalField, GeographicField...) and make interaction features for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_eng = train_dat.loc[:,cols]\n",
    "test_eng = test_dat.loc[:,cols]\n",
    "\n",
    "imp_col = sorted(bst.get_fscore().items(), key=lambda x: x[1])\n",
    "# Choose the most important features to create new interaction features\n",
    "int_col = imp_col[100:]\n",
    "-\n",
    "xg_train = xgb.DMatrix( train_eng.iloc[:samp].as_matrix(), label=train_labels[:samp], feature_names=train_eng.columns)\n",
    "xg_test = xgb.DMatrix( train_eng.iloc[samp:].as_matrix(), label=train_labels[samp:], feature_names=train_eng.columns)\n",
    "train_eng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param = {   'objective': 'binary:logistic',\n",
    "            'eval_metric': 'auc',\n",
    "            'nthread':4,\n",
    "            'booster':'gbtree'\n",
    "            'max_depth':6,\n",
    "            'colsample_bytree':0.77,\n",
    "            'subsample':0.83,\n",
    "            'min_child_weight':5,\n",
    "            'eta':0.023,\n",
    "        }\n",
    "watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "num_round = 1800\n",
    "model = xgb.train(param, xg_train, num_round, watchlist, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_model('eng_{}rounds.model'.format(num_round))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0.959776 best after 10 rounds\n",
    "- 0.962689 best after 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(model)\n",
    "plt.gcf().set_size_inches((10,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xg_pred = xgb.DMatrix( test_eng.as_matrix(), feature_names=test_eng.columns)\n",
    "pred = model.predict(xg_pred)\n",
    "sample = pd.read_csv('sample_submission.csv')\n",
    "sample.QuoteConversion_Flag = pred\n",
    "sample.to_csv('eng_02.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsne = manifold.TSNE(n_components=2, random_state=1010)\n",
    "tsne.fit(train_eng.iloc[0:1000].as_matrix(), train_labels[0:1000])\n",
    "print('Done fit')\n",
    "Y = tsne.fit_transform(train_eng.iloc[1000:3000].as_matrix())\n",
    "color = train_labels[1000:3000]\n",
    "plt.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Hyperparameter searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[See kaggle script](https://www.kaggle.com/phunter/flavours-of-physics/gridsearchcv-with-feature-in-xgboost/files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation, metrics, ensemble\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samp = int(len(train_dat)*0.95)\n",
    "print(samp)\n",
    "xg_train = xgb.DMatrix( train_dat.iloc[:samp].as_matrix(), label=train_labels[:samp])\n",
    "xg_test = xgb.DMatrix( train_dat.iloc[samp:].as_matrix(), label=train_labels[samp:])\n",
    "\n",
    "m = xgb.XGBClassifier()\n",
    "\n",
    "parameters = {'nthread':[4],\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05], #so called `eta` value\n",
    "              'max_depth': [6],\n",
    "              'min_child_weight': [5],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.75],\n",
    "              'n_estimators': [500, 750, 1000], #number of trees\n",
    "              'seed': [80085]}\n",
    "\n",
    "def auc_score(clf, X, y):\n",
    "    pred_prob = clf.predict_proba(X)[:,1]\n",
    "    return metrics.roc_auc_score(y, pred_prob)\n",
    "\n",
    "\n",
    "clf = GridSearchCV(m, parameters, n_jobs=1, \n",
    "                cv=cross_validation.StratifiedKFold(train_labels[samp:],\n",
    "                n_folds=5, shuffle=True), \n",
    "                scoring=auc_score,\n",
    "                verbose=2, refit=True)\n",
    "\n",
    "clf.fit(train_dat.iloc[:samp], train_labels[:samp])\n",
    "\n",
    "best_parameters, score, _ = max(clf.grid_scores_, key=lambda x: x[1])\n",
    "print('Raw AUC score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
